{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib1eurxuDp_a"
      },
      "outputs": [],
      "source": [
        "%pip install -q \"labelbox[data]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erxwZ6iUDp_b"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "import json\n",
        "import requests\n",
        "import labelbox as lb\n",
        "import labelbox.types as lb_types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m66YNOKNDp_c"
      },
      "source": [
        "### Replace with your API key\n",
        "Guides on https://docs.labelbox.com/docs/create-an-api-key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPZUx41EDp_c"
      },
      "outputs": [],
      "source": [
        "# Add your api key\n",
        "API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbHo2ejJ6MDAwMGtiMDd5YjU2Nms2eHBmIiwib3JnYW5pemF0aW9uSWQiOiJjbHo2ejJ5enUwMGthMDd5YmEwbXo2MnMwIiwiYXBpS2V5SWQiOiJjbHo3NGJmZ3EwNGtmMDd3NDI4eWVhYjF0Iiwic2VjcmV0IjoiZGFlNjljNzRlMjAzMGQxY2I5ODRiZDYyMWIzNWNmMGEiLCJpYXQiOjE3MjIyNjUzNDIsImV4cCI6MjM1MzQxNzM0Mn0.QMd4lc4NcebLdN3vyOlD0GNWa71vrkcryhO-e0xwZNs\"\n",
        "client = lb.Client(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BeifWpcDp_c"
      },
      "source": [
        "### Supported Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPkxtsbfDp_c"
      },
      "outputs": [],
      "source": [
        "########## Entity ##########\n",
        "\n",
        "# Annotation Types\n",
        "entities_annotations = lb_types.ObjectAnnotation(\n",
        "    name=\"named_entity\",\n",
        "    value=lb_types.DocumentEntity(\n",
        "        name=\"named_entity\",\n",
        "        textSelections=[\n",
        "            lb_types.DocumentTextSelection(token_ids=[], group_id=\"\", page=1)\n",
        "        ],\n",
        "    ),\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "entities_annotations_ndjson = {\n",
        "    \"name\":\n",
        "        \"named_entity\",\n",
        "    \"textSelections\": [{\n",
        "        \"tokenIds\": [\"<UUID>\",],\n",
        "        \"groupId\": \"<UUID>\",\n",
        "        \"page\": 1,\n",
        "    }],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhKuRrPkDp_c"
      },
      "outputs": [],
      "source": [
        "########### Radio Classification #########\n",
        "\n",
        "# Annotation types\n",
        "radio_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"radio_question\",\n",
        "    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "        name=\"first_radio_answer\")),\n",
        ")\n",
        "# NDJSON\n",
        "radio_annotation_ndjson = {\n",
        "    \"name\": \"radio_question\",\n",
        "    \"answer\": {\n",
        "        \"name\": \"first_radio_answer\"\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JY8cQYnvDp_d"
      },
      "outputs": [],
      "source": [
        "############ Checklist Classification ###########\n",
        "\n",
        "# Annotation types\n",
        "checklist_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"checklist_question\",\n",
        "    value=lb_types.Checklist(answer=[\n",
        "        lb_types.ClassificationAnswer(name=\"first_checklist_answer\"),\n",
        "        lb_types.ClassificationAnswer(name=\"second_checklist_answer\"),\n",
        "    ]),\n",
        ")\n",
        "\n",
        "# NDJSON\n",
        "checklist_annotation_ndjson = {\n",
        "    \"name\":\n",
        "        \"checklist_question\",\n",
        "    \"answer\": [\n",
        "        {\n",
        "            \"name\": \"first_checklist_answer\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"second_checklist_answer\"\n",
        "        },\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSo-H_wiDp_d"
      },
      "outputs": [],
      "source": [
        "############ Bounding Box ###########\n",
        "\n",
        "bbox_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"bounding_box\",  # must match your ontology feature\"s name\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=102.771, y=135.3),  # x = left, y = top\n",
        "        end=lb_types.Point(x=518.571,\n",
        "                           y=245.143),  # x= left + width , y = top + height\n",
        "        page=0,\n",
        "        unit=lb_types.RectangleUnit.POINTS,\n",
        "    ),\n",
        ")\n",
        "\n",
        "bbox_annotation_ndjson = {\n",
        "    \"name\": \"bounding_box\",\n",
        "    \"bbox\": {\n",
        "        \"top\": 135.3,\n",
        "        \"left\": 102.771,\n",
        "        \"height\": 109.843,\n",
        "        \"width\": 415.8\n",
        "    },\n",
        "    \"page\": 0,\n",
        "    \"unit\": \"POINTS\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40pB0CdZDp_d"
      },
      "outputs": [],
      "source": [
        "# ############ global nested classifications ###########\n",
        "\n",
        "nested_checklist_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"nested_checklist_question\",\n",
        "    value=lb_types.Checklist(answer=[\n",
        "        lb_types.ClassificationAnswer(\n",
        "            name=\"first_checklist_answer\",\n",
        "            classifications=[\n",
        "                lb_types.ClassificationAnnotation(\n",
        "                    name=\"sub_checklist_question\",\n",
        "                    value=lb_types.Checklist(answer=[\n",
        "                        lb_types.ClassificationAnswer(\n",
        "                            name=\"first_sub_checklist_answer\")\n",
        "                    ]),\n",
        "                )\n",
        "            ],\n",
        "        )\n",
        "    ]),\n",
        ")\n",
        "\n",
        "nested_checklist_annotation_ndjson = {\n",
        "    \"name\":\n",
        "        \"nested_checklist_question\",\n",
        "    \"answer\": [{\n",
        "        \"name\":\n",
        "            \"first_checklist_answer\",\n",
        "        \"classifications\": [{\n",
        "            \"name\": \"sub_checklist_question\",\n",
        "            \"answer\": {\n",
        "                \"name\": \"first_sub_checklist_answer\"\n",
        "            },\n",
        "        }],\n",
        "    }],\n",
        "}\n",
        "\n",
        "nested_radio_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"nested_radio_question\",\n",
        "    value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "        name=\"first_radio_answer\",\n",
        "        classifications=[\n",
        "            lb_types.ClassificationAnnotation(\n",
        "                name=\"sub_radio_question\",\n",
        "                value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "                    name=\"first_sub_radio_answer\")),\n",
        "            )\n",
        "        ],\n",
        "    )),\n",
        ")\n",
        "\n",
        "nested_radio_annotation_ndjson = {\n",
        "    \"name\": \"nested_radio_question\",\n",
        "    \"answer\": {\n",
        "        \"name\":\n",
        "            \"first_radio_answer\",\n",
        "        \"classifications\": [{\n",
        "            \"name\": \"sub_radio_question\",\n",
        "            \"answer\": {\n",
        "                \"name\": \"first_sub_radio_answer\"\n",
        "            },\n",
        "        }],\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHFyEoSkDp_d"
      },
      "outputs": [],
      "source": [
        "############## Classification Free-form text ##############\n",
        "\n",
        "text_annotation = lb_types.ClassificationAnnotation(\n",
        "    name=\"free_text\",  # must match your ontology feature\"s name\n",
        "    value=lb_types.Text(answer=\"sample text\"),\n",
        ")\n",
        "\n",
        "text_annotation_ndjson = {\"name\": \"free_text\", \"answer\": \"sample text\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yd3J_ChDp_e"
      },
      "outputs": [],
      "source": [
        "######### BBOX with nested classifications #########\n",
        "\n",
        "bbox_with_radio_subclass_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"bbox_with_radio_subclass\",\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=317.271, y=226.757),  # x = left, y = top\n",
        "        end=lb_types.Point(x=566.657,\n",
        "                           y=420.986),  # x= left + width , y = top + height\n",
        "        unit=lb_types.RectangleUnit.POINTS,\n",
        "        page=1,\n",
        "    ),\n",
        "    classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "            name=\"sub_radio_question\",\n",
        "            value=lb_types.Radio(answer=lb_types.ClassificationAnswer(\n",
        "                name=\"first_sub_radio_answer\",\n",
        "                classifications=[\n",
        "                    lb_types.ClassificationAnnotation(\n",
        "                        name=\"second_sub_radio_question\",\n",
        "                        value=lb_types.Radio(\n",
        "                            answer=lb_types.ClassificationAnswer(\n",
        "                                name=\"second_sub_radio_answer\")),\n",
        "                    )\n",
        "                ],\n",
        "            )),\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "bbox_with_radio_subclass_annotation_ndjson = {\n",
        "    \"name\": \"bbox_with_radio_subclass\",\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_radio_question\",\n",
        "        \"answer\": {\n",
        "            \"name\":\n",
        "                \"first_sub_radio_answer\",\n",
        "            \"classifications\": [{\n",
        "                \"name\": \"second_sub_radio_question\",\n",
        "                \"answer\": {\n",
        "                    \"name\": \"second_sub_radio_answer\"\n",
        "                },\n",
        "            }],\n",
        "        },\n",
        "    }],\n",
        "    \"bbox\": {\n",
        "        \"top\": 226.757,\n",
        "        \"left\": 317.271,\n",
        "        \"height\": 194.229,\n",
        "        \"width\": 249.386,\n",
        "    },\n",
        "    \"page\": 1,\n",
        "    \"unit\": \"POINTS\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qusn5oU0Dp_e"
      },
      "outputs": [],
      "source": [
        "############ NER with nested classifications ########\n",
        "\n",
        "ner_with_checklist_subclass_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"ner_with_checklist_subclass\",\n",
        "    value=lb_types.DocumentEntity(\n",
        "        name=\"ner_with_checklist_subclass\",\n",
        "        text_selections=[\n",
        "            lb_types.DocumentTextSelection(token_ids=[], group_id=\"\", page=1)\n",
        "        ],\n",
        "    ),\n",
        "    classifications=[\n",
        "        lb_types.ClassificationAnnotation(\n",
        "            name=\"sub_checklist_question\",\n",
        "            value=lb_types.Checklist(answer=[\n",
        "                lb_types.ClassificationAnswer(name=\"first_sub_checklist_answer\")\n",
        "            ]),\n",
        "        )\n",
        "    ],\n",
        ")\n",
        "\n",
        "ner_with_checklist_subclass_annotation_ndjson = {\n",
        "    \"name\":\n",
        "        \"ner_with_checklist_subclass\",\n",
        "    \"classifications\": [{\n",
        "        \"name\": \"sub_checklist_question\",\n",
        "        \"answer\": [{\n",
        "            \"name\": \"first_sub_checklist_answer\"\n",
        "        }],\n",
        "    }],\n",
        "    \"textSelections\": [{\n",
        "        \"tokenIds\": [\"<UUID>\"],\n",
        "        \"groupId\": \"<UUID>\",\n",
        "        \"page\": 1\n",
        "    }],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sdGQjDvDp_e"
      },
      "outputs": [],
      "source": [
        "######### Relationships ##########\n",
        "entity_source = lb_types.ObjectAnnotation(\n",
        "    name=\"named_entity\",\n",
        "    value=lb_types.DocumentEntity(\n",
        "        name=\"named_entity\",\n",
        "        textSelections=[\n",
        "            lb_types.DocumentTextSelection(token_ids=[], group_id=\"\", page=1)\n",
        "        ],\n",
        "    ),\n",
        ")\n",
        "\n",
        "entity_target = lb_types.ObjectAnnotation(\n",
        "    name=\"named_entity\",\n",
        "    value=lb_types.DocumentEntity(\n",
        "        name=\"named_entity\",\n",
        "        textSelections=[\n",
        "            lb_types.DocumentTextSelection(token_ids=[], group_id=\"\", page=1)\n",
        "        ],\n",
        "    ),\n",
        ")\n",
        "\n",
        "entity_relationship = lb_types.RelationshipAnnotation(\n",
        "    name=\"relationship\",\n",
        "    value=lb_types.Relationship(\n",
        "        source=entity_source,\n",
        "        target=entity_target,\n",
        "        type=lb_types.Relationship.Type.UNIDIRECTIONAL,\n",
        "    ),\n",
        ")\n",
        "\n",
        "## Only supported for MAL imports\n",
        "uuid_source = str(uuid.uuid4())\n",
        "uuid_target = str(uuid.uuid4())\n",
        "\n",
        "entity_source_ndjson = {\n",
        "    \"name\":\n",
        "        \"named_entity\",\n",
        "    \"uuid\":\n",
        "        uuid_source,\n",
        "    \"textSelections\": [{\n",
        "        \"tokenIds\": [\"<UUID>\"],\n",
        "        \"groupId\": \"<UUID>\",\n",
        "        \"page\": 1\n",
        "    }],\n",
        "}\n",
        "\n",
        "entity_target_ndjson = {\n",
        "    \"name\":\n",
        "        \"named_entity\",\n",
        "    \"uuid\":\n",
        "        uuid_target,\n",
        "    \"textSelections\": [{\n",
        "        \"tokenIds\": [\"<UUID>\"],\n",
        "        \"groupId\": \"<UUID>\",\n",
        "        \"page\": 1\n",
        "    }],\n",
        "}\n",
        "ner_relationship_annotation_ndjson = {\n",
        "    \"name\": \"relationship\",\n",
        "    \"relationship\": {\n",
        "        \"source\": uuid_source,\n",
        "        \"target\": uuid_target,\n",
        "        \"type\": \"unidirectional\",\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPqQYpNJDp_f"
      },
      "outputs": [],
      "source": [
        "######### BBOX with relationships #############\n",
        "# Python Annotation\n",
        "bbox_source = lb_types.ObjectAnnotation(\n",
        "    name=\"bounding_box\",\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=188.257, y=68.875),  # x = left, y = top\n",
        "        end=lb_types.Point(x=270.907,\n",
        "                           y=149.556),  # x = left + width , y = top + height\n",
        "        unit=lb_types.RectangleUnit.POINTS,\n",
        "        page=1,\n",
        "    ),\n",
        ")\n",
        "\n",
        "bbox_target = lb_types.ObjectAnnotation(\n",
        "    name=\"bounding_box\",\n",
        "    value=lb_types.DocumentRectangle(\n",
        "        start=lb_types.Point(x=96.424, y=66.251),\n",
        "        end=lb_types.Point(x=179.074, y=146.932),\n",
        "        unit=lb_types.RectangleUnit.POINTS,\n",
        "        page=1,\n",
        "    ),\n",
        ")\n",
        "\n",
        "bbox_relationship = lb_types.RelationshipAnnotation(\n",
        "    name=\"relationship\",\n",
        "    value=lb_types.Relationship(\n",
        "        source=bbox_source,\n",
        "        target=bbox_target,\n",
        "        type=lb_types.Relationship.Type.UNIDIRECTIONAL,\n",
        "    ),\n",
        ")\n",
        "\n",
        "## Only supported for MAL imports\n",
        "uuid_source_2 = str(uuid.uuid4())\n",
        "uuid_target_2 = str(uuid.uuid4())\n",
        "\n",
        "bbox_source_ndjson = {\n",
        "    \"name\": \"bounding_box\",\n",
        "    \"uuid\": uuid_source_2,\n",
        "    \"bbox\": {\n",
        "        \"top\": 68.875,\n",
        "        \"left\": 188.257,\n",
        "        \"height\": 80.681,\n",
        "        \"width\": 82.65\n",
        "    },\n",
        "    \"page\": 1,\n",
        "    \"unit\": \"POINTS\",\n",
        "}\n",
        "\n",
        "bbox_target_ndjson = {\n",
        "    \"name\": \"bounding_box\",\n",
        "    \"uuid\": uuid_target_2,\n",
        "    \"bbox\": {\n",
        "        \"top\": 66.251,\n",
        "        \"left\": 96.424,\n",
        "        \"height\": 80.681,\n",
        "        \"width\": 82.65\n",
        "    },\n",
        "    \"page\": 1,\n",
        "    \"unit\": \"POINTS\",\n",
        "}\n",
        "\n",
        "bbox_relationship_annotation_ndjson = {\n",
        "    \"name\": \"relationship\",\n",
        "    \"relationship\": {\n",
        "        \"source\": uuid_source_2,\n",
        "        \"target\": uuid_target_2,\n",
        "        \"type\": \"unidirectional\",\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cydRIIpFcpM"
      },
      "source": [
        "# Upload Annotations - putting it all together\n",
        "### Step 1: Download the PDF file from github or any other sources.\n",
        "### Step 2: Upload the PDF to a Cloud Storage Service\n",
        "### Step 3: Use the New PDF URL in the Labelbox Workflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdfqgH0qLokY"
      },
      "outputs": [],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bekdHEWSLyLw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# GitHub file URL\n",
        "github_url = \"https://github.com/dlsucomet/MLResources/raw/master/books/%5BML%5D%20Introduction%20to%20Machine%20Learning%20with%20Python%20(2017).pdf\"\n",
        "\n",
        "response = requests.get(github_url)\n",
        "pdf_filename = \"ML_Introduction.pdf\"\n",
        "with open(pdf_filename, 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "print(f\"Downloaded PDF as {pdf_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0sn64fGL0V_"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Replace with your GCS project and bucket details\n",
        "bucket_name = 'your-gcs-bucket'\n",
        "destination_blob_name = pdf_filename\n",
        "source_file_name = pdf_filename\n",
        "\n",
        "# Initialize a storage client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Upload the PDF to GCS\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(destination_blob_name)\n",
        "blob.upload_from_filename(source_file_name)\n",
        "\n",
        "# Get the public URL of the uploaded file\n",
        "pdf_url = f\"https://storage.googleapis.com/{bucket_name}/{destination_blob_name}\"\n",
        "print(f\"Uploaded PDF to {pdf_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfGFcptsNgoz"
      },
      "outputs": [],
      "source": [
        "import labelbox as lb\n",
        "import uuid\n",
        "\n",
        "global_key = \"ML_Introduction.pdf\" + str(uuid.uuid4())\n",
        "img_url = {\n",
        "    \"row_data\": {\n",
        "        \"pdf_url\": pdf_url\n",
        "    },\n",
        "    \"global_key\": global_key,\n",
        "}\n",
        "\n",
        "dataset = client.create_dataset(name=\"pdf_demo_dataset\")\n",
        "task = dataset.create_data_rows([img_url])\n",
        "task.wait_till_done()\n",
        "print(f\"Failed data rows: {task.failed_data_rows}\")\n",
        "print(f\"Errors: {task.errors}\")\n",
        "\n",
        "if task.errors:\n",
        "    for error in task.errors:\n",
        "        if (\"Duplicate global key\" in error[\"message\"] and\n",
        "                dataset.row_count == 0):\n",
        "            print(f\"Deleting empty dataset: {dataset}\")\n",
        "            dataset.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w4-8YApDp_f"
      },
      "source": [
        "### Step 2: Create/select an Ontology for your project\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjJllLqQDp_g"
      },
      "outputs": [],
      "source": [
        "## Setup the ontology and link the tools created above.\n",
        "\n",
        "ontology_builder = lb.OntologyBuilder(\n",
        "    classifications=[  # List of Classification objects\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.RADIO,\n",
        "            name=\"radio_question\",\n",
        "            scope=lb.Classification.Scope.GLOBAL,\n",
        "            options=[\n",
        "                lb.Option(value=\"first_radio_answer\"),\n",
        "                lb.Option(value=\"second_radio_answer\"),\n",
        "            ],\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"checklist_question\",\n",
        "            scope=lb.Classification.Scope.GLOBAL,\n",
        "            options=[\n",
        "                lb.Option(value=\"first_checklist_answer\"),\n",
        "                lb.Option(value=\"second_checklist_answer\"),\n",
        "            ],\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.TEXT,\n",
        "            name=\"free_text\",\n",
        "            scope=lb.Classification.Scope.GLOBAL,\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.RADIO,\n",
        "            name=\"nested_radio_question\",\n",
        "            scope=lb.Classification.Scope.GLOBAL,\n",
        "            options=[\n",
        "                lb.Option(\n",
        "                    \"first_radio_answer\",\n",
        "                    options=[\n",
        "                        lb.Classification(\n",
        "                            class_type=lb.Classification.Type.RADIO,\n",
        "                            name=\"sub_radio_question\",\n",
        "                            options=[lb.Option(\"first_sub_radio_answer\")],\n",
        "                        )\n",
        "                    ],\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "        lb.Classification(\n",
        "            class_type=lb.Classification.Type.CHECKLIST,\n",
        "            name=\"nested_checklist_question\",\n",
        "            scope=lb.Classification.Scope.GLOBAL,\n",
        "            options=[\n",
        "                lb.Option(\n",
        "                    \"first_checklist_answer\",\n",
        "                    options=[\n",
        "                        lb.Classification(\n",
        "                            class_type=lb.Classification.Type.CHECKLIST,\n",
        "                            name=\"sub_checklist_question\",\n",
        "                            options=[lb.Option(\"first_sub_checklist_answer\")],\n",
        "                        )\n",
        "                    ],\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        "    tools=[  # List of Tool objects\n",
        "        lb.Tool(tool=lb.Tool.Type.BBOX, name=\"bounding_box\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.NER, name=\"named_entity\"),\n",
        "        lb.Tool(tool=lb.Tool.Type.RELATIONSHIP, name=\"relationship\"),\n",
        "        lb.Tool(\n",
        "            tool=lb.Tool.Type.NER,\n",
        "            name=\"ner_with_checklist_subclass\",\n",
        "            classifications=[\n",
        "                lb.Classification(\n",
        "                    class_type=lb.Classification.Type.CHECKLIST,\n",
        "                    name=\"sub_checklist_question\",\n",
        "                    options=[lb.Option(value=\"first_sub_checklist_answer\")],\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "        lb.Tool(\n",
        "            tool=lb.Tool.Type.BBOX,\n",
        "            name=\"bbox_with_radio_subclass\",\n",
        "            classifications=[\n",
        "                lb.Classification(\n",
        "                    class_type=lb.Classification.Type.RADIO,\n",
        "                    name=\"sub_radio_question\",\n",
        "                    options=[\n",
        "                        lb.Option(\n",
        "                            value=\"first_sub_radio_answer\",\n",
        "                            options=[\n",
        "                                lb.Classification(\n",
        "                                    class_type=lb.Classification.Type.RADIO,\n",
        "                                    name=\"second_sub_radio_question\",\n",
        "                                    options=[\n",
        "                                        lb.Option(\"second_sub_radio_answer\")\n",
        "                                    ],\n",
        "                                )\n",
        "                            ],\n",
        "                        )\n",
        "                    ],\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "ontology = client.create_ontology(\n",
        "    \"Document Annotation Import Demo\",\n",
        "    ontology_builder.asdict(),\n",
        "    media_type=lb.MediaType.Document,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mczWgyVDp_g"
      },
      "source": [
        "### Step 3: Creating a labeling project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s57RCusDDp_g"
      },
      "outputs": [],
      "source": [
        "# Create a Labelbox project\n",
        "project = client.create_project(name=\"PDF_annotation_demo\",\n",
        "                                media_type=lb.MediaType.Document)\n",
        "project.setup_editor(ontology)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YW6U91mDp_g"
      },
      "source": [
        "### Step 4: Send a batch of data rows to the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMUyjqqMDp_g"
      },
      "outputs": [],
      "source": [
        "project.create_batch(\n",
        "    \"PDF_annotation_batch\",  # Each batch in a project must have a unique name\n",
        "    global_keys=[\n",
        "        global_key\n",
        "    ],  # Paginated collection of data row objects, list of data row ids or global keys\n",
        "    priority=5,  # priority between 1(Highest) - 5(lowest)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiH7PUMWDp_h"
      },
      "source": [
        "### Step 5. Create the annotation payload\n",
        "Create the annotations payload using the snippets of code in Supported predictions section.\n",
        "\n",
        "Labelbox support NDJSON only for this data type.\n",
        "\n",
        "The resulting label should have exactly the same content for annotations that are supported by both (with exception of the uuid strings that are generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp5Xjo5BDp_h"
      },
      "source": [
        "##### Step 5.1: First, we need to populate the text selections for Entity annotations\n",
        "To import ner annotations, you must pass a `text_layer_url`, Labelbox automatically generates a `text_layer_url` after importing a pdf asset that doesn't include a `text_layer_url`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWpjF8O8Dp_h"
      },
      "source": [
        "To extract the generated text layer url we first need to export the data row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzqtMmvkDp_h"
      },
      "outputs": [],
      "source": [
        "client.enable_experimental = True\n",
        "task = lb.DataRow.export(client=client, global_keys=[global_key])\n",
        "task.wait_till_done()\n",
        "stream = task.get_buffered_stream()\n",
        "\n",
        "text_layer = \"\"\n",
        "for output in stream:\n",
        "    output_json = output.json\n",
        "    text_layer = output_json[\"media_attributes\"][\"text_layer_url\"]\n",
        "print(text_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSdiqYxwDp_h"
      },
      "outputs": [],
      "source": [
        "# Helper method\n",
        "def update_text_selections(annotation, group_id, list_tokens, page):\n",
        "    return annotation.update({\n",
        "        \"textSelections\": [{\n",
        "            \"groupId\": group_id,\n",
        "            \"tokenIds\": list_tokens,\n",
        "            \"page\": page\n",
        "        }]\n",
        "    })\n",
        "\n",
        "\n",
        "# Fetch the content of the text layer\n",
        "res = requests.get(text_layer)\n",
        "\n",
        "# Phrases that we want to annotation obtained from the text layer url\n",
        "content_phrases = [\n",
        "    \"Metal-insulator (MI) transitions have been one of the\",\n",
        "    \"T. Sasaki, N. Yoneyama, and N. Kobayashi\",\n",
        "    \"Organic charge transfer salts based on the donor\",\n",
        "    \"the experimental investigations on this issue have not\",\n",
        "]\n",
        "\n",
        "# Parse the text layer\n",
        "text_selections = []\n",
        "text_selections_ner = []\n",
        "text_selections_source = []\n",
        "text_selections_target = []\n",
        "\n",
        "for obj in json.loads(res.text):\n",
        "    for group in obj[\"groups\"]:\n",
        "        if group[\"content\"] == content_phrases[0]:\n",
        "            list_tokens = [x[\"id\"] for x in group[\"tokens\"]]\n",
        "            # build text selections for Python Annotation Types\n",
        "            document_text_selection = lb_types.DocumentTextSelection(\n",
        "                groupId=group[\"id\"], tokenIds=list_tokens, page=1)\n",
        "            text_selections.append(document_text_selection)\n",
        "            # build text selection for the NDJson annotations\n",
        "            update_text_selections(\n",
        "                annotation=entities_annotations_ndjson,\n",
        "                group_id=group[\"id\"],  # id representing group of words\n",
        "                list_tokens=\n",
        "                list_tokens,  # ids representing individual words from the group\n",
        "                page=1,\n",
        "            )\n",
        "        if group[\"content\"] == content_phrases[1]:\n",
        "            list_tokens_2 = [x[\"id\"] for x in group[\"tokens\"]]\n",
        "            # build text selections for Python Annotation Types\n",
        "            ner_text_selection = lb_types.DocumentTextSelection(\n",
        "                groupId=group[\"id\"], tokenIds=list_tokens_2, page=1)\n",
        "            text_selections_ner.append(ner_text_selection)\n",
        "            # build text selection for the NDJson annotations\n",
        "            update_text_selections(\n",
        "                annotation=ner_with_checklist_subclass_annotation_ndjson,\n",
        "                group_id=group[\"id\"],  # id representing group of words\n",
        "                list_tokens=\n",
        "                list_tokens_2,  # ids representing individual words from the group\n",
        "                page=1,\n",
        "            )\n",
        "        if group[\"content\"] == content_phrases[2]:\n",
        "            relationship_source = [x[\"id\"] for x in group[\"tokens\"]]\n",
        "            # build text selections for Python Annotation Types\n",
        "            text_selection_entity_source = lb_types.DocumentTextSelection(\n",
        "                groupId=group[\"id\"], tokenIds=relationship_source, page=1)\n",
        "            text_selections_source.append(text_selection_entity_source)\n",
        "            # build text selection for the NDJson annotations\n",
        "            update_text_selections(\n",
        "                annotation=entity_source_ndjson,\n",
        "                group_id=group[\"id\"],  # id representing group of words\n",
        "                list_tokens=\n",
        "                relationship_source,  # ids representing individual words from the group\n",
        "                page=1,\n",
        "            )\n",
        "        if group[\"content\"] == content_phrases[3]:\n",
        "            relationship_target = [x[\"id\"] for x in group[\"tokens\"]]\n",
        "            # build text selections for Python Annotation Types\n",
        "            text_selection_entity_target = lb_types.DocumentTextSelection(\n",
        "                group_id=group[\"id\"], tokenIds=relationship_target, page=1)\n",
        "            text_selections_target.append(text_selection_entity_target)\n",
        "            # build text selections forthe NDJson annotations\n",
        "            update_text_selections(\n",
        "                annotation=entity_target_ndjson,\n",
        "                group_id=group[\"id\"],  # id representing group of words\n",
        "                list_tokens=\n",
        "                relationship_target,  # ids representing individual words from the group\n",
        "                page=1,\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xridqdpjDp_h"
      },
      "source": [
        "Re-write the python annotations to include text selections (only required for python annotation types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jv6ykZivDp_i"
      },
      "outputs": [],
      "source": [
        "# re-write the entity annotation with text selections\n",
        "entities_annotation_document_entity = lb_types.DocumentEntity(\n",
        "    name=\"named_entity\", textSelections=text_selections)\n",
        "entities_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"named_entity\", value=entities_annotation_document_entity)\n",
        "\n",
        "# re-write the entity annotation + subclassification with text selections\n",
        "classifications = [\n",
        "    lb_types.ClassificationAnnotation(\n",
        "        name=\"sub_checklist_question\",\n",
        "        value=lb_types.Checklist(answer=[\n",
        "            lb_types.ClassificationAnswer(name=\"first_sub_checklist_answer\")\n",
        "        ]),\n",
        "    )\n",
        "]\n",
        "ner_annotation_with_subclass = lb_types.DocumentEntity(\n",
        "    name=\"ner_with_checklist_subclass\", textSelections=text_selections_ner)\n",
        "ner_with_checklist_subclass_annotation = lb_types.ObjectAnnotation(\n",
        "    name=\"ner_with_checklist_subclass\",\n",
        "    value=ner_annotation_with_subclass,\n",
        "    classifications=classifications,\n",
        ")\n",
        "\n",
        "# re-write the entity source and target annotations withe text selectios\n",
        "entity_source_doc = lb_types.DocumentEntity(\n",
        "    name=\"named_entity\", text_selections=text_selections_source)\n",
        "entity_source = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
        "                                          value=entity_source_doc)\n",
        "\n",
        "entity_target_doc = lb_types.DocumentEntity(\n",
        "    name=\"named_entity\", text_selections=text_selections_target)\n",
        "entity_target = lb_types.ObjectAnnotation(name=\"named_entity\",\n",
        "                                          value=entity_target_doc)\n",
        "\n",
        "# re-write the entity relationship with the re-created entities\n",
        "entity_relationship = lb_types.RelationshipAnnotation(\n",
        "    name=\"relationship\",\n",
        "    value=lb_types.Relationship(\n",
        "        source=entity_source,\n",
        "        target=entity_target,\n",
        "        type=lb_types.Relationship.Type.UNIDIRECTIONAL,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U14GUaoDp_i"
      },
      "outputs": [],
      "source": [
        "# Final NDJSON and python annotations\n",
        "print(f\"entities_annotations_ndjson={entities_annotations_ndjson}\")\n",
        "print(f\"entities_annotation={entities_annotation}\")\n",
        "print(\n",
        "    f\"nested_entities_annotation_ndjson={ner_with_checklist_subclass_annotation_ndjson}\"\n",
        ")\n",
        "print(f\"nested_entities_annotation={ner_with_checklist_subclass_annotation}\")\n",
        "print(f\"entity_source_ndjson={entity_source_ndjson}\")\n",
        "print(f\"entity_target_ndjson={entity_target_ndjson}\")\n",
        "print(f\"entity_source={entity_source}\")\n",
        "print(f\"entity_target={entity_target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blw8WbUiDp_i"
      },
      "source": [
        "#### Python annotation\n",
        "Here we create the complete labels ndjson payload of annotations only using python annotation format. There is one annotation for each reference to an annotation that we created. Note that only a handful of python annotation types are supported for PDF documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMUPsYb3Dp_i"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "\n",
        "labels.append(\n",
        "    lb_types.Label(\n",
        "        data={\"global_key\": global_key},\n",
        "        annotations=[\n",
        "            entities_annotation,\n",
        "            checklist_annotation,\n",
        "            nested_checklist_annotation,\n",
        "            text_annotation,\n",
        "            radio_annotation,\n",
        "            nested_radio_annotation,\n",
        "            bbox_annotation,\n",
        "            bbox_with_radio_subclass_annotation,\n",
        "            ner_with_checklist_subclass_annotation,\n",
        "            entity_source,\n",
        "            entity_target,\n",
        "            entity_relationship,  # Only supported for MAL imports\n",
        "            bbox_source,\n",
        "            bbox_target,\n",
        "            bbox_relationship,  # Only supported for MAL imports\n",
        "        ],\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ufVDkQ3Dp_i"
      },
      "source": [
        "#### NDJson annotations\n",
        "Here we create the complete labels ndjson payload of annotations only using NDJSON format. There is one annotation for each reference to an annotation that we created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b2PaMgBDp_j"
      },
      "outputs": [],
      "source": [
        "label_ndjson = []\n",
        "for annot in [\n",
        "        entities_annotations_ndjson,\n",
        "        checklist_annotation_ndjson,\n",
        "        nested_checklist_annotation_ndjson,\n",
        "        text_annotation_ndjson,\n",
        "        radio_annotation_ndjson,\n",
        "        nested_radio_annotation_ndjson,\n",
        "        bbox_annotation_ndjson,\n",
        "        bbox_with_radio_subclass_annotation_ndjson,\n",
        "        ner_with_checklist_subclass_annotation_ndjson,\n",
        "        entity_source_ndjson,\n",
        "        entity_target_ndjson,\n",
        "        ner_relationship_annotation_ndjson,  # Only supported for MAL imports\n",
        "        bbox_source_ndjson,\n",
        "        bbox_target_ndjson,\n",
        "        bbox_relationship_annotation_ndjson,  # Only supported for MAL imports\n",
        "]:\n",
        "    annot.update({\n",
        "        \"dataRow\": {\n",
        "            \"globalKey\": global_key\n",
        "        },\n",
        "    })\n",
        "    label_ndjson.append(annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trxtEpa0Dp_j"
      },
      "source": [
        "### Step 6: Import the annotation payload\n",
        "For the purpose of this tutorial only import one of the annotations payloads at the time (NDJSON or Python annotation types)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s35S9ijDp_j"
      },
      "source": [
        "Option A: Upload to a labeling project as pre-labels (MAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgOQe81HDp_j"
      },
      "outputs": [],
      "source": [
        "upload_job = lb.MALPredictionImport.create_from_objects(\n",
        "    client=client,\n",
        "    project_id=project.uid,\n",
        "    name=\"pdf_annotation_upload\" + str(uuid.uuid4()),\n",
        "    predictions=labels,\n",
        ")\n",
        "\n",
        "upload_job.wait_until_done()\n",
        "# Errors will appear for annotation uploads that failed.\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d151KfqGDp_j"
      },
      "source": [
        "Option B: Upload to a labeling project using ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o-_ouBfDp_j"
      },
      "outputs": [],
      "source": [
        "# Uncomment this code when excluding relationships from label import\n",
        "# Relationships are not currently supported for label import\n",
        "\n",
        "upload_job = lb.LabelImport.create_from_objects(\n",
        "    client = client,\n",
        "    project_id = project.uid,\n",
        "    name=\"label_import_job\"+str(uuid.uuid4()),\n",
        "    labels=labels) ## Remove unsupported relationships from the labels list\n",
        "\n",
        "print(\"Errors:\", upload_job.errors)\n",
        "print(\"Status of uploads: \", upload_job.statuses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4HsB-y-I2_D"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
